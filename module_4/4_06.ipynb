{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo NLP: Entrenamiento con Hyperparameter Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'module_4/part_05'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685385470294.dkr.ecr.eu-west-1.amazonaws.com/blazingtext:1\n"
     ]
    }
   ],
   "source": [
    "image=sagemaker.image_uris.retrieve(framework='blazingtext', \n",
    "                                    region=region, \n",
    "                                    version='1')\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-west-1-467432373215/module_4/part_05/train\n",
      "s3://sagemaker-eu-west-1-467432373215/module_4/part_05/validation\n"
     ]
    }
   ],
   "source": [
    "train_channel = prefix + '/train'\n",
    "s3_train_data = f's3://{bucket}/{train_channel}'\n",
    "validation_channel = prefix + '/validation'\n",
    "s3_validation_data = f's3://{bucket}/{validation_channel}'\n",
    "print(s3_train_data)\n",
    "print(s3_validation_data)\n",
    "\n",
    "data_channels = {'train': s3_train_data, \n",
    "                 'validation': s3_validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Experimento variando el learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Tenemos los siguentes hyperparametros que podemos optimizar: https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/blazingtext_hyperparameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "experiment_name = f'dbpedia-text-classification-lr-{now}'\n",
    "\n",
    "try:\n",
    "    experiment = Experiment.create(\n",
    "        experiment_name=experiment_name, \n",
    "        description='Training a text classification model using dbpedia dataset.')\n",
    "except ClientError as e:\n",
    "    print(f'{experiment_name} experiment already exists! Reusing the existing experiment.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: dbpedia-blazingtext-2024-05-24-13-37-46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted training job dbpedia-blazingtext-2024-05-24-13-37-46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: dbpedia-blazingtext-2024-05-24-13-37-48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted training job dbpedia-blazingtext-2024-05-24-13-37-48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: dbpedia-blazingtext-2024-05-24-13-37-49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted training job dbpedia-blazingtext-2024-05-24-13-37-49\n"
     ]
    }
   ],
   "source": [
    "s3_output_location = f's3://{bucket}/{prefix}/output-lr'\n",
    "\n",
    "for lr in [0.1, 0.01, 0.001]:\n",
    "    now = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    jobname = f'dbpedia-blazingtext-{now}'\n",
    "\n",
    "    # Creating a new trial for the experiment\n",
    "    exp_trial = Trial.create(\n",
    "        experiment_name=experiment_name, \n",
    "        trial_name=jobname)\n",
    "\n",
    "    experiment_config={\n",
    "        'ExperimentName': experiment_name,\n",
    "        'TrialName': exp_trial.trial_name,\n",
    "        'TrialComponentDisplayName': 'Training'}\n",
    "    \n",
    "    estimator = sagemaker.estimator.Estimator(\n",
    "        image,\n",
    "        role,\n",
    "        instance_count=1,\n",
    "        instance_type='ml.c5.2xlarge',\n",
    "        volume_size=30,\n",
    "        max_run=3600,\n",
    "        input_mode='File',\n",
    "        enable_sagemaker_metrics=True,\n",
    "        output_path=s3_output_location,\n",
    "        hyperparameters={\n",
    "            'mode': 'supervised',\n",
    "            'epochs': 40,\n",
    "            'min_count': 2,\n",
    "            'learning_rate': lr,\n",
    "            'vector_dim': 10,\n",
    "            'early_stopping': True,\n",
    "            'patience': 4,\n",
    "            'min_epochs': 5,\n",
    "            'word_ngrams': 2\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    estimator.fit(\n",
    "        inputs=data_channels,\n",
    "        job_name=jobname,\n",
    "        experiment_config=experiment_config,\n",
    "        wait=False, # This allow to continue in the for loop\n",
    "    )\n",
    "    print(f'Submitted training job {jobname}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuner search\n",
    "- Amazon SageMaker HyperparameterTuner busca la mejor versión de un modelo al ejecutar muchos trabajos de entrenamiento en el conjunto de datos mediante el algoritmo y los rangos de hiperparámetros que especifique.\n",
    "- Elige los valores de hiperparámetros que dan lugar a un modelo con el mejor rendimiento medido por una métrica.\n",
    "- https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html\n",
    "- Esta vez usaremos spot instances: https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/model-managed-spot-training.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_output_location = f's3://{bucket}/{prefix}/output-hyper-opt'\n",
    "\n",
    "jobname = f'dbpedia-blazingtext-hyper-new'\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.2xlarge',\n",
    "    use_spot_instances=True, # They can stop our trainings\n",
    "    max_run=60*10,\n",
    "    max_wait=60*10,\n",
    "    volume_size=30,\n",
    "    input_mode='File',\n",
    "    enable_sagemaker_metrics=True,\n",
    "    output_path=s3_output_location,\n",
    "    hyperparameters={\n",
    "        'mode': 'supervised',\n",
    "        'epochs': 40,\n",
    "        'min_count': 2,\n",
    "        #'vector_dim': 10,\n",
    "        #'learning_rate': 0.05,\n",
    "        'early_stopping': True,\n",
    "        'patience': 4,\n",
    "        'min_epochs': 5,\n",
    "        #'word_ngrams': 2\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://sagemaker.readthedocs.io/en/stable/api/training/parameter.html#sagemaker.parameter.ParameterRange\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": sagemaker.parameter.ContinuousParameter(min_value=0.001, max_value=0.1, scaling_type='Logarithmic'),\n",
    "    \"vector_dim\": sagemaker.parameter.IntegerParameter(min_value=5, max_value=15),\n",
    "    \"word_ngrams\": sagemaker.parameter.IntegerParameter(min_value=1, max_value=5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "tuner = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator,\n",
    "    \"validation:accuracy\",\n",
    "    hyperparameter_ranges,\n",
    "    objective_type='Maximize',\n",
    "    max_jobs=20,\n",
    "    max_parallel_jobs=10,\n",
    "    strategy=\"Random\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: dbpedia-blazingtext-hyper-new\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................."
     ]
    }
   ],
   "source": [
    "tuner.fit(    \n",
    "    inputs=data_channels,\n",
    "    job_name=jobname,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Podemos ver los resultados con HyperparameterTuningJobAnalytics.\n",
    "- También podemos verlo en la pantalla de experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'job_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df\u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39mHyperparameterTuningJobAnalytics(\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_tuning_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\n\u001b[1;32m      3\u001b[0m )\u001b[38;5;241m.\u001b[39mdataframe()\n\u001b[1;32m      4\u001b[0m df\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'job_name'"
     ]
    }
   ],
   "source": [
    "df= sagemaker.HyperparameterTuningJobAnalytics(\n",
    "    tuner.latest_tuning_job.job_name\n",
    ").dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.sort_values(by='FinalObjectiveValue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[\n",
    "    :, ['FinalObjectiveValue', 'learning_rate']\n",
    "].set_index('learning_rate').sort_index().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[\n",
    "    :, ['FinalObjectiveValue', 'vector_dim']\n",
    "].set_index('vector_dim').sort_index().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[\n",
    "    :, ['FinalObjectiveValue', 'word_ngrams']\n",
    "].set_index('word_ngrams').sort_index().plot()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
