{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is developed using the `Python 3 (Data Science)` kernel on an `ml.t3.medium` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'sagemaker-studio-book/chapter05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=sagemaker.image_uris.retrieve(framework='blazingtext', \n",
    "                                    region=region, \n",
    "                                    version='1')\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = f's3://{bucket}/{prefix}/output'\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "            image,\n",
    "            role,\n",
    "            instance_count=1,\n",
    "            instance_type='ml.c5.2xlarge',\n",
    "            volume_size=30,\n",
    "            max_run=360000,\n",
    "            input_mode='File',\n",
    "            enable_sagemaker_metrics=True,\n",
    "            output_path=s3_output_location,\n",
    "            hyperparameters={\n",
    "                'mode': 'supervised',\n",
    "                'epochs': 20,\n",
    "                'min_count': 2,\n",
    "                'learning_rate': 0.05,\n",
    "                'vector_dim': 10,\n",
    "                'early_stopping': True,\n",
    "                'patience': 4,\n",
    "                'min_epochs': 5,\n",
    "                'word_ngrams': 2,\n",
    "            },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "\n",
    "sess.upload_data(path='dbpedia_csv/dbpedia.train', bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path='dbpedia_csv/dbpedia.validation', bucket=bucket, key_prefix=validation_channel)\n",
    "\n",
    "s3_train_data = f's3://{bucket}/{train_channel}'\n",
    "s3_validation_data = f's3://{bucket}/{validation_channel}'\n",
    "print(s3_train_data)\n",
    "print(s3_validation_data)\n",
    "\n",
    "data_channels = {'train': s3_train_data, \n",
    "                 'validation': s3_validation_data}\n",
    "\n",
    "exp_datetime = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n",
    "jobname = f'dbpedia-blazingtext-{exp_datetime}'\n",
    "\n",
    "estimator.fit(inputs=data_channels,\n",
    "              job_name=jobname,\n",
    "              logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {estimator.model_data} ./dbpedia_csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "cd dbpedia_csv/\n",
    "tar -zxf model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "experiment_name = 'dbpedia-text-classification'\n",
    "\n",
    "try:\n",
    "    experiment = Experiment.create(\n",
    "        experiment_name=experiment_name, \n",
    "        description='Training a text classification model using dbpedia dataset.')\n",
    "except ClientError as e:\n",
    "    print(f'{experiment_name} experiment already exists! Reusing the existing experiment.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in [0.1, 0.01, 0.001]:\n",
    "    \n",
    "    exp_datetime = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n",
    "    jobname = f'dbpedia-blazingtext-{exp_datetime}'\n",
    "\n",
    "    # Creating a new trial for the experiment\n",
    "    exp_trial = Trial.create(\n",
    "        experiment_name=experiment_name, \n",
    "        trial_name=jobname)\n",
    "\n",
    "    experiment_config={\n",
    "        'ExperimentName': experiment_name,\n",
    "        'TrialName': exp_trial.trial_name,\n",
    "        'TrialComponentDisplayName': 'Training'}\n",
    "    \n",
    "    estimator = sagemaker.estimator.Estimator(\n",
    "                    image,\n",
    "                    role,\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.c5.2xlarge',\n",
    "                    volume_size=30,\n",
    "                    max_run=360000,\n",
    "                    input_mode='File',\n",
    "                    enable_sagemaker_metrics=True,\n",
    "                    output_path=s3_output_location,\n",
    "                    hyperparameters={\n",
    "                        'mode': 'supervised',\n",
    "                        'epochs': 40,\n",
    "                        'min_count': 2,\n",
    "                        'learning_rate': lr,\n",
    "                        'vector_dim': 10,\n",
    "                        'early_stopping': True,\n",
    "                        'patience': 4,\n",
    "                        'min_epochs': 5,\n",
    "                        'word_ngrams': 2},\n",
    "    )\n",
    "    \n",
    "    estimator.fit(\n",
    "             inputs=data_channels,\n",
    "             job_name=jobname,\n",
    "             experiment_config=experiment_config,\n",
    "             wait=False)\n",
    "    print(f'Submitted training job {jobname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
