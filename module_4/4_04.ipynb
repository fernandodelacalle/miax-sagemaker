{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9532a1d5-e96d-4cca-bbf4-9305478c03db",
   "metadata": {},
   "source": [
    "# Modelo NLP: Preparación de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0282d380-43df-4241-b9e3-023d1553d923",
   "metadata": {},
   "source": [
    "- Usaremos la base de datos DBPedia Ontology Dataset  ( Zhang et al. https://arxiv.org/pdf/1509.01626.pdf ) \n",
    "- 12 clases, con 560,000 ejemplos de entrenamiento y  70,000 de test.\n",
    "- El texto contiene el título y el resumen de cada artículo de la Wikipedia.\n",
    "- El algorítmo que vamos a usar, BlazingText, espera un único fichero de texto plano donode cada linea contenga la etiqueta “_*label_*” precedida por y la frase.\n",
    "- Este notebook realiza todo el procesado para obtener los ficheros para realizar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218b6fc-4d5e-44d1-b38f-431609af27f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip dbpedia_csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804bc13-97fc-4380-805b-aa11b51b4116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!head dbpedia_csv/train.csv -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7feac7-4161-4d9f-b904-c055984d40bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!grep -i \"automatic electric\"  dbpedia_csv/train.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce85cd-9caa-405b-8f23-4ead4c47fdc9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat dbpedia_csv/classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4b29a-7677-499f-9063-11781088bcd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_label = {}\n",
    "with open('dbpedia_csv/classes.txt') as f:\n",
    "    for i, label in enumerate(f.readlines()):\n",
    "        d_label[str(i + 1)] = label.strip()\n",
    "print(d_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a013ef3-01a9-4367-bda1-6a6a7b712a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed54db24-efdf-49fc-9ea8-36befda9a4a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_text(row):\n",
    "    cur_row = []\n",
    "    label = f'__label__{d_label[row[0]]}'  # Prefix the index-ed label with __label__\n",
    "    cur_row.append(label)\n",
    "    cur_row.extend(nltk.word_tokenize(row[1].lower()))\n",
    "    cur_row.extend(nltk.word_tokenize(row[2].lower()))\n",
    "    return cur_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2032f87c-edfb-418e-87ec-b218f98cedf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import csv\n",
    "\n",
    "def preprocess(input_file, output_file, keep=1):\n",
    "    all_rows = []\n",
    "    with open(input_file, 'r') as csvinfile:\n",
    "        csv_reader = csv.reader(csvinfile, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            all_rows.append(row)\n",
    "    shuffle(all_rows)\n",
    "    all_rows = all_rows[: int(keep * len(all_rows))]\n",
    "    pool = Pool(processes=multiprocessing.cpu_count())\n",
    "    transformed_rows = pool.map(transform_text, all_rows)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    with open(output_file, 'w') as csvoutfile:\n",
    "        csv_writer = csv.writer(csvoutfile, delimiter=' ', lineterminator='\\n')\n",
    "        csv_writer.writerows(transformed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa08b1cc-396e-4d2c-9bc0-164803eed0f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "preprocess('dbpedia_csv/train.csv', 'dbpedia_csv/dbpedia.train', keep=0.2)\n",
    "preprocess('dbpedia_csv/test.csv', 'dbpedia_csv/dbpedia.validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30f4e91-ddfa-425c-8004-7bd028d190b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!head -n 5 dbpedia_csv/dbpedia.train"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
